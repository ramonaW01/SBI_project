{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "#  Protein Binding Pocket Finder\n",
    "\n",
    "This notebook implements a geometry-based algorithm for predicting **ligand binding pockets** in protein structures.\n",
    "\n",
    "## Principle\n",
    "Instead of computing expensive energy functions, the protein surface is sampled geometrically:\n",
    "1. A 3D grid of points is placed over the entire protein\n",
    "2. Points that are too close to the protein (collision) or too far away (empty space) are removed\n",
    "3. The remaining points — located inside cavities and pockets — are grouped into clusters\n",
    "4. Each cluster corresponds to one potential binding pocket\n",
    "\n",
    "Binding pockets are often **evolutionarily conserved**: residues that form a functional site tend to be invariant across species. This is used as an additional filter after the geometric step.\n",
    "\n",
    "## Input\n",
    "A `.pdb` file (here: `1H8D.pdb` — a serine protease from the RCSB Protein Data Bank)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-md",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    "\n",
    "All required libraries are imported here in one central place:\n",
    "- **`numpy`** – fast array operations and vector math\n",
    "- **`Bio.PDB`** – Biopython module for reading and analyzing PDB files\n",
    "- **`scipy.spatial.KDTree`** – efficient spatial lookups (much faster than naive distance calculations)\n",
    "- **`sklearn.cluster.DBSCAN`** – density-based clustering algorithm that requires no fixed cluster count\n",
    "- **`Bio.AlignIO`** – reading Multiple Sequence Alignments (MSA) for conservation scoring\n",
    "- **`collections.Counter`** – frequency counting for conservation score calculation\n",
    "- **`time`** – runtime measurement\n",
    "- **`os`** – directory creation for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "from Bio import PDB, AlignIO\n",
    "from Bio.PDB import is_aa\n",
    "from Bio.PDB.Polypeptide import is_aa\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Reading the Protein Structure\n",
    "PDB files contain not only the protein atoms, but also water molecules, ligands, ions, and other hetero-atoms.\n",
    "\n",
    "For binding site prediction, we only keep atoms belonging to the protein itself.\n",
    "\n",
    "### Why filter?\n",
    "\n",
    "* **Water molecules** introduce noise because their positions are often not biologically stable.\n",
    "* **Ligands and co-factors** may already occupy binding pockets and would bias the prediction.\n",
    "\n",
    "### Filtering in BioPython\n",
    "\n",
    "The structure is parsed using BioPython and iterated hierarchically:\n",
    "\n",
    "Structure → Model → Chain → Residue → Atom\n",
    "\n",
    "We use:\n",
    "\n",
    "```python\n",
    "is_aa(residue, standard=True)\n",
    "```\n",
    "\n",
    "to select only the 20 standard amino acids.\n",
    "\n",
    "This automatically excludes:\n",
    "\n",
    "* water (HOH)\n",
    "* ligands\n",
    "* ions\n",
    "* co-factors\n",
    "\n",
    "### Example PDB records\n",
    "\n",
    "```\n",
    "ATOM      1  N   ALA A   1 ...\n",
    "HETATM 1234  O   HOH A 201 ...\n",
    "HETATM 2345 FE   HEM A 500 ...\n",
    "```\n",
    "\n",
    "Only `ATOM` records corresponding to amino acids are kept.\n",
    "\n",
    "The resulting atom list is used for grid generation in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "step1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protein_structure(pdb_file: str):\n",
    "    \"\"\"\n",
    "    Reads a PDB file and returns the structure object along with a list\n",
    "    of all protein atoms (excluding water and ligands).\n",
    "\n",
    "    Parameters:\n",
    "        pdb_file: Path to the .pdb file\n",
    "\n",
    "    Returns:\n",
    "        structure:     Bio.PDB Structure object (full hierarchy)\n",
    "        protein_atoms: List of all Atom objects belonging to amino acids\n",
    "    \"\"\"\n",
    "    # QUIET=True suppresses warnings for minor format inconsistencies\n",
    "    # PERMISSIVE=True allows non-standard PDB entries\n",
    "    parser = PDB.PDBParser(QUIET=True, PERMISSIVE=True)\n",
    "\n",
    "    # Load the structure — 'protein_obj' is an internal label for the object\n",
    "    structure = parser.get_structure('protein_obj', pdb_file)\n",
    "\n",
    "    protein_atoms = []\n",
    "\n",
    "    # Hierarchical iteration: Model → Chain → Residue → Atom\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                # robust protein check: only standard amino acids\n",
    "                if not is_aa(residue, standard=True):\n",
    "                    continue\n",
    "\n",
    "                for atom in residue:\n",
    "                    protein_atoms.append(atom)\n",
    "\n",
    "    print(f\"Loaded: {len(protein_atoms)} protein atoms found.\")\n",
    "    return structure, protein_atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1b-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 1b. Saving a Cleaned PDB File\n",
    "\n",
    "Raw PDB files often contain multiple chains, water molecules, and ligands that are not relevant for pocket prediction.\n",
    "`save_clean_protein` creates a new, minimal PDB file containing **only the selected protein chain(s)** with standard amino acids.\n",
    "\n",
    "### Why save a clean file?\n",
    "\n",
    "* Reduces file size and complexity for downstream tools\n",
    "* Ensures consistent chain labelling for all subsequent steps\n",
    "* Avoids artefacts from co-crystallised ligands or water molecules that could bias the grid filtering\n",
    "\n",
    "The function builds a fresh BioPython `Structure` object, copies only the desired chains and amino-acid residues,\n",
    "and writes the result with `PDBIO`. Only residues passing `is_aa(standard=True)` are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "step1b-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBIO\n",
    "from Bio.PDB.Structure import Structure\n",
    "from Bio.PDB.Model import Model\n",
    "from Bio.PDB.Chain import Chain\n",
    "\n",
    "\n",
    "def save_clean_protein(structure, output_file, protein_chains=[\"H\"]):\n",
    "    \"\"\"\n",
    "    Saves a cleaned PDB containing only the specified chains and\n",
    "    standard amino acids (no water, ligands, or ions).\n",
    "\n",
    "    Parameters:\n",
    "        structure:      Bio.PDB Structure object (full, unfiltered)\n",
    "        output_file:    Path for the output .pdb file\n",
    "        protein_chains: List of chain IDs to retain (default: ['H'])\n",
    "    \"\"\"\n",
    "    clean_structure = Structure(\"clean\")\n",
    "    model_new = Model(0)\n",
    "    clean_structure.add(model_new)\n",
    "\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            # Keep only the desired chains\n",
    "            if chain.id not in protein_chains:\n",
    "                continue\n",
    "\n",
    "            new_chain = Chain(chain.id)\n",
    "\n",
    "            for residue in chain:\n",
    "                if is_aa(residue, standard=True):\n",
    "                    new_chain.add(residue.copy())\n",
    "\n",
    "            model_new.add(new_chain)\n",
    "\n",
    "    io = PDBIO()\n",
    "    io.set_structure(clean_structure)\n",
    "    io.save(output_file)\n",
    "\n",
    "    print(\"Clean protein saved:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1c-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 1c. Loading and Cleaning the Protein\n",
    "\n",
    "This cell executes the loading and cleaning pipeline:\n",
    "\n",
    "1. **Load original PDB** (`1H8D.pdb`) — reads all atoms including ligands, water, and multiple chains.\n",
    "2. **Save cleaned PDB** (`1H8D_cleaned.pdb`) — retains only chain H with standard amino acids.\n",
    "3. **Reload cleaned file** — `clean_atoms` is used by all subsequent steps.\n",
    "4. **Verification printout** — lists every residue in the cleaned chain.\n",
    "\n",
    "> **Note:** Chain `H` is specific to `1H8D`. Adjust `protein_chains` for other PDB entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "step1c-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 2333 protein atoms found.\n",
      "Clean protein saved: 1H8D_cleaned.pdb\n",
      "Loaded: 2030 protein atoms found.\n",
      "\n",
      "Atom count: original=2333, cleaned=2030\n",
      "Removed: 303 atoms (ligands, water, other chains)\n",
      "\n",
      "VERIFY CLEANED FILE:\n",
      "\n",
      "CHAIN: H\n",
      "ILE\n",
      "VAL\n",
      "GLU\n",
      "GLY\n",
      "SER\n",
      "ASP\n",
      "ALA\n",
      "GLU\n",
      "ILE\n",
      "GLY\n",
      "MET\n",
      "SER\n",
      "PRO\n",
      "TRP\n",
      "GLN\n",
      "VAL\n",
      "MET\n",
      "LEU\n",
      "PHE\n",
      "ARG\n",
      "LYS\n",
      "SER\n",
      "PRO\n",
      "GLN\n",
      "GLU\n",
      "LEU\n",
      "LEU\n",
      "CYS\n",
      "GLY\n",
      "ALA\n",
      "SER\n",
      "LEU\n",
      "ILE\n",
      "SER\n",
      "ASP\n",
      "ARG\n",
      "TRP\n",
      "VAL\n",
      "LEU\n",
      "THR\n",
      "ALA\n",
      "ALA\n",
      "HIS\n",
      "CYS\n",
      "LEU\n",
      "LEU\n",
      "TYR\n",
      "PRO\n",
      "PRO\n",
      "TRP\n",
      "ASP\n",
      "LYS\n",
      "ASN\n",
      "PHE\n",
      "THR\n",
      "GLU\n",
      "ASN\n",
      "ASP\n",
      "LEU\n",
      "LEU\n",
      "VAL\n",
      "ARG\n",
      "ILE\n",
      "GLY\n",
      "LYS\n",
      "HIS\n",
      "SER\n",
      "ARG\n",
      "THR\n",
      "ARG\n",
      "TYR\n",
      "GLU\n",
      "ARG\n",
      "ASN\n",
      "ILE\n",
      "GLU\n",
      "LYS\n",
      "ILE\n",
      "SER\n",
      "MET\n",
      "LEU\n",
      "GLU\n",
      "LYS\n",
      "ILE\n",
      "TYR\n",
      "ILE\n",
      "HIS\n",
      "PRO\n",
      "ARG\n",
      "TYR\n",
      "ASN\n",
      "TRP\n",
      "ARG\n",
      "GLU\n",
      "ASN\n",
      "LEU\n",
      "ASP\n",
      "ARG\n",
      "ASP\n",
      "ILE\n",
      "ALA\n",
      "LEU\n",
      "MET\n",
      "LYS\n",
      "LEU\n",
      "LYS\n",
      "LYS\n",
      "PRO\n",
      "VAL\n",
      "ALA\n",
      "PHE\n",
      "SER\n",
      "ASP\n",
      "TYR\n",
      "ILE\n",
      "HIS\n",
      "PRO\n",
      "VAL\n",
      "CYS\n",
      "LEU\n",
      "PRO\n",
      "ASP\n",
      "ARG\n",
      "GLU\n",
      "THR\n",
      "ALA\n",
      "ALA\n",
      "SER\n",
      "LEU\n",
      "LEU\n",
      "GLN\n",
      "ALA\n",
      "GLY\n",
      "TYR\n",
      "LYS\n",
      "GLY\n",
      "ARG\n",
      "VAL\n",
      "THR\n",
      "GLY\n",
      "TRP\n",
      "GLY\n",
      "ASN\n",
      "LEU\n",
      "LYS\n",
      "GLU\n",
      "THR\n",
      "GLY\n",
      "GLN\n",
      "PRO\n",
      "SER\n",
      "VAL\n",
      "LEU\n",
      "GLN\n",
      "VAL\n",
      "VAL\n",
      "ASN\n",
      "LEU\n",
      "PRO\n",
      "ILE\n",
      "VAL\n",
      "GLU\n",
      "ARG\n",
      "PRO\n",
      "VAL\n",
      "CYS\n",
      "LYS\n",
      "ASP\n",
      "SER\n",
      "THR\n",
      "ARG\n",
      "ILE\n",
      "ARG\n",
      "ILE\n",
      "THR\n",
      "ASP\n",
      "ASN\n",
      "MET\n",
      "PHE\n",
      "CYS\n",
      "ALA\n",
      "GLY\n",
      "TYR\n",
      "LYS\n",
      "PRO\n",
      "ASP\n",
      "GLU\n",
      "GLY\n",
      "LYS\n",
      "ARG\n",
      "GLY\n",
      "ASP\n",
      "ALA\n",
      "CYS\n",
      "GLU\n",
      "GLY\n",
      "ASP\n",
      "SER\n",
      "GLY\n",
      "GLY\n",
      "PRO\n",
      "PHE\n",
      "VAL\n",
      "MET\n",
      "LYS\n",
      "SER\n",
      "PRO\n",
      "PHE\n",
      "ASN\n",
      "ASN\n",
      "ARG\n",
      "TRP\n",
      "TYR\n",
      "GLN\n",
      "MET\n",
      "GLY\n",
      "ILE\n",
      "VAL\n",
      "SER\n",
      "TRP\n",
      "GLY\n",
      "GLU\n",
      "GLY\n",
      "CYS\n",
      "ASP\n",
      "ARG\n",
      "ASP\n",
      "GLY\n",
      "LYS\n",
      "TYR\n",
      "GLY\n",
      "PHE\n",
      "TYR\n",
      "THR\n",
      "HIS\n",
      "VAL\n",
      "PHE\n",
      "ARG\n",
      "LEU\n",
      "LYS\n",
      "LYS\n",
      "TRP\n",
      "ILE\n",
      "GLN\n",
      "LYS\n",
      "VAL\n",
      "ILE\n",
      "ASP\n",
      "GLN\n",
      "PHE\n",
      "GLY\n",
      "CYS\n",
      "SER\n",
      "SER\n",
      "VAL\n",
      "LEU\n",
      "ILE\n",
      "VAL\n",
      "VAL\n",
      "CYS\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = \"1H8D.pdb\"\n",
    "\n",
    "# Step 1: Load original structure (all chains, ligands, water)\n",
    "structure, atoms = get_protein_structure(FILE_PATH)\n",
    "\n",
    "# Step 2: Save cleaned file (chain H, amino acids only)\n",
    "save_clean_protein(structure, \"1H8D_cleaned.pdb\", protein_chains=[\"H\"])\n",
    "\n",
    "# Step 3: Reload cleaned file — this is the input for all following steps\n",
    "clean_structure, clean_atoms = get_protein_structure(\"1H8D_cleaned.pdb\")\n",
    "\n",
    "print(f\"\\nAtom count: original={len(atoms)}, cleaned={len(clean_atoms)}\")\n",
    "print(f\"Removed: {len(atoms) - len(clean_atoms)} atoms (ligands, water, other chains)\\n\")\n",
    "\n",
    "print(\"VERIFY CLEANED FILE:\\n\")\n",
    "for model in clean_structure:\n",
    "    for chain in model:\n",
    "        print(\"CHAIN:\", chain.id)\n",
    "        for residue in chain:\n",
    "            print(residue.get_resname())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1d-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 1d. Verifying the Cleaned Structure\n",
    "\n",
    "Before proceeding, we confirm that no hetero-atoms remain.\n",
    "A blank hetero flag (`' '`) means the residue is a standard amino acid — the expected result.\n",
    "Any `'H_'` prefix would indicate a remaining hetero-atom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "step1d-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON-PROTEIN RESIDUES IN CLEANED FILE:\n",
      "\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: MET | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: TRP | Hetero flag: ' '\n",
      "Chain: H | Name: GLN | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: MET | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: PHE | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: GLN | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: CYS | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: TRP | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: THR | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: HIS | Hetero flag: ' '\n",
      "Chain: H | Name: CYS | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: TRP | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: PHE | Hetero flag: ' '\n",
      "Chain: H | Name: THR | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: HIS | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: THR | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: MET | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: HIS | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: TRP | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: MET | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: PHE | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: HIS | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: CYS | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: THR | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: GLN | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: THR | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: TRP | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: THR | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: GLN | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: GLN | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: CYS | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: THR | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: THR | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: MET | Hetero flag: ' '\n",
      "Chain: H | Name: PHE | Hetero flag: ' '\n",
      "Chain: H | Name: CYS | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: ALA | Hetero flag: ' '\n",
      "Chain: H | Name: CYS | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: PHE | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: MET | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: PRO | Hetero flag: ' '\n",
      "Chain: H | Name: PHE | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: ASN | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: TRP | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: GLN | Hetero flag: ' '\n",
      "Chain: H | Name: MET | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: TRP | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: GLU | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: CYS | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: PHE | Hetero flag: ' '\n",
      "Chain: H | Name: TYR | Hetero flag: ' '\n",
      "Chain: H | Name: THR | Hetero flag: ' '\n",
      "Chain: H | Name: HIS | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: PHE | Hetero flag: ' '\n",
      "Chain: H | Name: ARG | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: TRP | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: GLN | Hetero flag: ' '\n",
      "Chain: H | Name: LYS | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: ASP | Hetero flag: ' '\n",
      "Chain: H | Name: GLN | Hetero flag: ' '\n",
      "Chain: H | Name: PHE | Hetero flag: ' '\n",
      "Chain: H | Name: GLY | Hetero flag: ' '\n",
      "Chain: H | Name: CYS | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: SER | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: LEU | Hetero flag: ' '\n",
      "Chain: H | Name: ILE | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: VAL | Hetero flag: ' '\n",
      "Chain: H | Name: CYS | Hetero flag: ' '\n"
     ]
    }
   ],
   "source": [
    "print(\"NON-PROTEIN RESIDUES IN CLEANED FILE:\\n\")\n",
    "for model in clean_structure:\n",
    "    for chain in model:\n",
    "        for residue in chain:\n",
    "            hetflag = residue.id[0]\n",
    "            print(f\"Chain: {chain.id} | Name: {residue.get_resname()} | Hetero flag: {hetflag!r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Creating the Search Grid\n",
    "\n",
    "To search for potential binding sites, we place a regular 3D grid around the protein.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "| Parameter | Meaning                      | Typical Value                  |\n",
    "| --------- | ---------------------------- | ------------------------------ |\n",
    "| `spacing` | Distance between grid points | 2.0 Å (testing), 1.0 Å (final) |\n",
    "| `buffer`  | Extra space around protein   | 5.0 Å                          |\n",
    "\n",
    "### Method\n",
    "\n",
    "First, the bounding box of the protein is computed from the atom coordinates.\n",
    "Then, evenly spaced points are generated along each axis using `np.arange()` and\n",
    "combined into 3D coordinates using `np.meshgrid()`.\n",
    "\n",
    "The result is a NumPy array of shape `(N, 3)` where each row is one grid point.\n",
    "\n",
    "### Note on Performance\n",
    "\n",
    "Smaller spacing increases resolution but dramatically increases the number of grid points\n",
    "(~8× more when going from 2.0 Å to 1.0 Å)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "step2-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Grid created: 174,900 points at 1.0 Å spacing.\n"
     ]
    }
   ],
   "source": [
    "def create_search_grid(protein_atoms: list, spacing: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates a uniform 3D grid around the protein.\n",
    "\n",
    "    Parameters:\n",
    "        protein_atoms: List of Biopython Atom objects\n",
    "        spacing:       Distance between grid points in Ångström\n",
    "\n",
    "    Returns:\n",
    "        grid: numpy array of shape (N, 3) containing N grid points\n",
    "    \"\"\"\n",
    "    BUFFER = 5.0  # Å — padding region extending beyond the protein\n",
    "\n",
    "    # Extract all atom coordinates into a single (N, 3) matrix\n",
    "    coords = np.array([atom.get_coord() for atom in protein_atoms])\n",
    "\n",
    "    # Bounding box: smallest and largest coordinates along x, y, z\n",
    "    min_coords = coords.min(axis=0) - BUFFER\n",
    "    max_coords = coords.max(axis=0) + BUFFER\n",
    "\n",
    "    # Generate axis arrays\n",
    "    x = np.arange(min_coords[0], max_coords[0], spacing)\n",
    "    y = np.arange(min_coords[1], max_coords[1], spacing)\n",
    "    z = np.arange(min_coords[2], max_coords[2], spacing)\n",
    "\n",
    "    # Generate all (x, y, z) combinations and reshape into an (N, 3) matrix\n",
    "    grid = np.stack(np.meshgrid(x, y, z), axis=-1).reshape(-1, 3)\n",
    "\n",
    "    print(f\" Grid created: {grid.shape[0]:,} points at {spacing} Å spacing.\")\n",
    "    return grid\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "if 'clean_atoms' in locals():\n",
    "    grid = create_search_grid(clean_atoms, spacing=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Filtering Pocket Candidates\n",
    "\n",
    "The grid contains many irrelevant points. We keep only points near the protein surface using three successive distance filters.\n",
    "\n",
    "### Filter 1 — Collision check (`min_dist = 2.0 Å`)\n",
    "\n",
    "Points closer than 2.0 Å to any protein atom are inside the van-der-Waals radius and are discarded.\n",
    "\n",
    "---\n",
    "\n",
    "### Filter 2 — Surface proximity (`max_dist = 5.0 Å`)\n",
    "\n",
    "Points with no protein atom within 5.0 Å are in bulk solvent and are removed.\n",
    "This is intentionally stricter than the surface accessibility radius in Filter 3.\n",
    "\n",
    "---\n",
    "\n",
    "### Filter 3 — Surface accessibility check (`surface_threshold = 6.5 Å`)\n",
    "\n",
    "To exclude points trapped deep inside internal cavities, we count how many protein atoms are within 6.5 Å of each remaining candidate.\n",
    "\n",
    "* Points with **fewer than 25** neighbors are too isolated (noise or solvent) → removed\n",
    "* Points with **more than 50** neighbors are buried too deeply inside the protein → removed\n",
    "* Only points in the range **[25 – 50]** survive, representing surface-accessible pockets.\n",
    "\n",
    "---\n",
    "\n",
    "### Efficient search using KDTree\n",
    "\n",
    "All three filters use a single KDTree built once over all atom coordinates, reducing the computation from O(N²) to **O(N log N)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Result\n",
    "\n",
    "The output is a reduced NumPy array of shape `(M, 3)` representing candidate binding pocket locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "step3-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neighbor count in 6.5 Å radius -> Min: 2, Max: 77, Mean: 20.7\n",
      "Filtered: 174,900 → 5,009 pocket candidates (2.9% remaining).\n",
      "Runtime: 0.6s\n"
     ]
    }
   ],
   "source": [
    "def find_pocket_points(\n",
    "    grid_points: np.ndarray,\n",
    "    protein_atoms: list,\n",
    "    min_dist: float = 2.0,\n",
    "    max_dist: float = 5.0,\n",
    "    surface_threshold: float = 6.5,\n",
    "    min_neighbors: int = 32,\n",
    "    max_neighbors: int = 50\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Filters grid points down to potential binding pocket candidates.\n",
    "\n",
    "    Three successive filters are applied:\n",
    "        1. Collision check:       remove points closer than min_dist to any atom\n",
    "        2. Surface proximity:     remove points with no atom within max_dist\n",
    "        3. Surface accessibility: keep only points with atom count in\n",
    "                                  [min_neighbors, max_neighbors] within surface_threshold\n",
    "\n",
    "    Parameters:\n",
    "        grid_points:       numpy array (N, 3) of all grid points\n",
    "        protein_atoms:     list of Biopython Atom objects\n",
    "        min_dist:          collision radius (Å) — points inside protein are removed\n",
    "        max_dist:          surface proximity radius (Å) — bulk solvent points are removed\n",
    "        surface_threshold: neighbor-count radius (Å) — used for accessibility filter\n",
    "        min_neighbors:     minimum atom neighbors required (too few = isolated / solvent)\n",
    "        max_neighbors:     maximum atom neighbors allowed (too many = buried inside protein)\n",
    "\n",
    "    Returns:\n",
    "        pocket_points: numpy array (M, 3) of surviving candidate points\n",
    "    \"\"\"\n",
    "    if len(grid_points) == 0:\n",
    "        return np.empty((0, 3))\n",
    "\n",
    "    # Extract coordinates from Biopython objects\n",
    "    atom_coords = np.array([atom.get_coord() for atom in protein_atoms])\n",
    "\n",
    "    # Build the KDTree once — reused for all three filters\n",
    "    tree = KDTree(atom_coords)\n",
    "\n",
    "    # --- Filter 1: Collision check ---\n",
    "    # If any atom is within min_dist, the point is inside the protein → discard\n",
    "    clash_neighbors = tree.query_ball_point(grid_points, min_dist)\n",
    "    no_clash_mask = np.array([len(n) == 0 for n in clash_neighbors])\n",
    "    candidates = grid_points[no_clash_mask]\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        return np.empty((0, 3))\n",
    "\n",
    "    # --- Filter 2: Surface proximity ---\n",
    "    # Keep only points that have at least one atom within max_dist (not bulk solvent).\n",
    "    # max_dist is intentionally smaller than surface_threshold so this filter is not redundant.\n",
    "    surface_neighbors = tree.query_ball_point(candidates, max_dist)\n",
    "    near_surface_mask = np.array([len(n) > 0 for n in surface_neighbors])\n",
    "    candidates = candidates[near_surface_mask]\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        return np.empty((0, 3))\n",
    "\n",
    "    # --- Filter 3: Surface accessibility ---\n",
    "    # Count protein atoms within surface_threshold.\n",
    "    # Points with too few neighbors are isolated (solvent); too many are buried.\n",
    "    surface_access = tree.query_ball_point(candidates, surface_threshold)\n",
    "    neighbor_counts = [len(n) for n in surface_access]\n",
    "\n",
    "    print(f\" Neighbor count in {surface_threshold} Å radius -> \"\n",
    "          f\"Min: {min(neighbor_counts)}, Max: {max(neighbor_counts)}, \"\n",
    "          f\"Mean: {sum(neighbor_counts)/len(neighbor_counts):.1f}\")\n",
    "\n",
    "    surface_access_mask = np.array([\n",
    "        min_neighbors <= len(n) <= max_neighbors\n",
    "        for n in surface_access\n",
    "    ])\n",
    "    pocket_points = candidates[surface_access_mask]\n",
    "\n",
    "    print(f\"Filtered: {len(grid_points):,} → {len(pocket_points):,} pocket candidates \"\n",
    "          f\"({len(pocket_points)/len(grid_points)*100:.1f}% remaining).\")\n",
    "    return pocket_points\n",
    "\n",
    "\n",
    "# --- Execution with runtime measurement ---\n",
    "if 'clean_atoms' in locals() and 'grid' in locals():\n",
    "    start = time.time()\n",
    "    pocket_candidates = find_pocket_points(grid, clean_atoms)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Runtime: {elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cluster Analysis: Identifying Individual Pockets\n",
    "\n",
    "The filtered grid points are grouped into clusters to identify discrete candidate binding regions.\n",
    "Dense groups of neighboring points represent actual pockets; isolated points are noise.\n",
    "\n",
    "### Why DBSCAN instead of k-Means?\n",
    "- DBSCAN requires **no prior specification** of the number of clusters\n",
    "- DBSCAN detects clusters of arbitrary shape (pockets are irregular)\n",
    "- DBSCAN marks isolated outlier points as **noise** (label `-1`)\n",
    "\n",
    "### Parameters\n",
    "| Parameter | Meaning | Value used |\n",
    "|-----------|---------|------------|\n",
    "| `eps` | Maximum distance between two points in the same cluster | 1.5 Å |\n",
    "| `min_samples` | Minimum points required to form a cluster | 15 |\n",
    "| `MIN_POINTS` | Discard clusters smaller than this (too small to be a real pocket) | 60 |\n",
    "| `MAX_POINTS` | Discard clusters larger than this (likely a poorly separated surface region) | 1000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "step4-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pockets found (5009 noise points discarded):\n"
     ]
    }
   ],
   "source": [
    "def cluster_pocket_points(\n",
    "    pocket_points: np.ndarray,\n",
    "    eps: float = 1.2,\n",
    "    min_samples: int = 20,\n",
    "    MIN_POINTS: int = 60,\n",
    "    MAX_POINTS: int = 1000\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Groups pocket candidate points into discrete binding pockets using DBSCAN.\n",
    "\n",
    "    Parameters:\n",
    "        pocket_points: numpy array (N, 3) of filtered candidate points\n",
    "        eps:           maximum distance between two points in the same cluster (Å)\n",
    "        min_samples:   minimum number of points required to form a valid cluster\n",
    "        MIN_POINTS:    clusters smaller than this are discarded\n",
    "        MAX_POINTS:    clusters larger than this are discarded\n",
    "\n",
    "    Returns:\n",
    "        pockets: dict {rank_id: np.ndarray of points}, sorted largest first,\n",
    "                 with rank_ids as consecutive integers starting at 1\n",
    "    \"\"\"\n",
    "    if len(pocket_points) == 0:\n",
    "        print(\" No points available for clustering.\")\n",
    "        return {}\n",
    "\n",
    "    # Run DBSCAN clustering\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = db.fit_predict(pocket_points)\n",
    "\n",
    "    # Group points by cluster label (exclude noise label -1)\n",
    "    unique_labels = [label for label in set(labels) if label != -1]\n",
    "    raw_pockets = {\n",
    "        label: pocket_points[labels == label]\n",
    "        for label in unique_labels\n",
    "    }\n",
    "\n",
    "    # Sort by cluster size descending (largest = most likely binding site)\n",
    "    sorted_pockets = dict(\n",
    "        sorted(raw_pockets.items(), key=lambda item: len(item[1]), reverse=True)\n",
    "    )\n",
    "\n",
    "    # Filter too small and too large clusters, then re-index from 1\n",
    "    pockets = {\n",
    "        new_id: pts\n",
    "        for new_id, (_, pts) in enumerate(\n",
    "            ((label, pts) for label, pts in sorted_pockets.items()\n",
    "             if MIN_POINTS <= len(pts) <= MAX_POINTS),\n",
    "            start=1\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Print summary\n",
    "    noise_count = int(np.sum(labels == -1))\n",
    "    print(f\"{len(pockets)} pockets found ({noise_count} noise points discarded):\")\n",
    "\n",
    "    for p_id, p_points in pockets.items():\n",
    "        center = np.mean(p_points, axis=0)\n",
    "        print(f\"   Pocket {p_id}: {len(p_points):>4} points | Center: \"\n",
    "              f\"({center[0]:.1f}, {center[1]:.1f}, {center[2]:.1f})\")\n",
    "\n",
    "    return pockets\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "if 'pocket_candidates' in locals():\n",
    "    pockets_dict = cluster_pocket_points(pocket_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Export for Visualization in PyMOL / UCSF Chimera\n",
    "\n",
    "All pipeline stages are exported as **PDB files** so results can be inspected visually.\n",
    "Each grid point is written as a **HETATM dummy atom**.\n",
    "\n",
    "### Exported files\n",
    "\n",
    "| File | Description |\n",
    "| ----------------------------- | ------------------------------------ |\n",
    "| `step1_full_grid.pdb` | Complete 3D search grid |\n",
    "| `step2_pocket_candidates.pdb` | Filtered surface candidate points |\n",
    "| `step3_pocket_N.pdb` | Individual clustered binding pockets |\n",
    "\n",
    "### Why export?\n",
    "\n",
    "* Enables **visual validation** of the algorithm\n",
    "* Confirms pockets are located on the **protein surface**\n",
    "* Provides output for **further analysis or docking**\n",
    "\n",
    "**Workflow in PyMOL:**\n",
    "1. `File → Open → 1H8D_cleaned.pdb`\n",
    "2. `File → Open → step3_pocket_0.pdb` (repeat for each pocket)\n",
    "3. Select pocket object: `as spheres`\n",
    "4. Colour: `color red, pocket0` etc.\n",
    "\n",
    "**Workflow in UCSF Chimera:**\n",
    "1. `File → Open → 1H8D_cleaned.pdb`\n",
    "2. `File → Open → step3_pocket_0.pdb`\n",
    "3. `Actions → Atoms/Bonds → sphere`\n",
    "4. `Actions → Color → ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "step5-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1: Generating grid ...\n",
      " Grid created: 174,900 points at 1.0 Å spacing.\n",
      " Saved: pocket_output/step1_full_grid.pdb (174900 points)\n",
      "\n",
      "Step 2: Filtering candidates ...\n",
      " Neighbor count in 6.5 Å radius -> Min: 2, Max: 77, Mean: 20.7\n",
      "Filtered: 174,900 → 5,009 pocket candidates (2.9% remaining).\n",
      " Saved: pocket_output/step2_pocket_candidates.pdb (5009 points)\n",
      "\n",
      " Step 3: Clustering pockets ...\n",
      "0 pockets found (5009 noise points discarded):\n",
      "\n",
      " Exporting pockets ...\n",
      "\n",
      "Export complete. 0 pocket files saved.\n"
     ]
    }
   ],
   "source": [
    "def save_points_to_pdb(points: np.ndarray, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves a numpy array of 3D coordinates as a PDB file.\n",
    "    Each point is written as a HETATM entry (dummy atom 'P').\n",
    "\n",
    "    Atom serial numbers wrap at 99999 to stay within PDB column width.\n",
    "\n",
    "    Parameters:\n",
    "        points:      numpy array (N, 3) with XYZ coordinates\n",
    "        output_file: target file path\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        for i, (x, y, z) in enumerate(points):\n",
    "            # Wrap serial at 99999 to prevent column overflow in PDB format\n",
    "            serial = (i % 99999) + 1\n",
    "            f.write(\n",
    "                f\"HETATM{serial:5d}  P   PTS A   1    \"\n",
    "                f\"{x:8.3f}{y:8.3f}{z:8.3f}  1.00  0.00           P\\n\"\n",
    "            )\n",
    "        f.write(\"END\\n\")\n",
    "    print(f\" Saved: {output_file} ({len(points)} points)\")\n",
    "\n",
    "\n",
    "def export_all_steps(clean_atoms: list, output_dir: str = \".\") -> None:\n",
    "    \"\"\"\n",
    "    Runs the full geometry pipeline and exports each stage as a PDB file.\n",
    "\n",
    "    Output files:\n",
    "        step1_full_grid.pdb          — the complete grid around the protein\n",
    "        step2_pocket_candidates.pdb  — filtered pocket candidate points\n",
    "        step3_pocket_N.pdb           — individual clustered pockets (sorted by size)\n",
    "\n",
    "    Parameters:\n",
    "        clean_atoms: list of Biopython Atom objects (cleaned protein)\n",
    "        output_dir:  directory in which all PDB files are saved\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(\" Step 1: Generating grid ...\")\n",
    "    full_grid = create_search_grid(clean_atoms, spacing=1.0)\n",
    "    save_points_to_pdb(full_grid, f\"{output_dir}/step1_full_grid.pdb\")\n",
    "\n",
    "    print(\"\\nStep 2: Filtering candidates ...\")\n",
    "    candidates = find_pocket_points(full_grid, clean_atoms)\n",
    "    save_points_to_pdb(candidates, f\"{output_dir}/step2_pocket_candidates.pdb\")\n",
    "\n",
    "    print(\"\\n Step 3: Clustering pockets ...\")\n",
    "    pockets = cluster_pocket_points(candidates)\n",
    "\n",
    "    print(\"\\n Exporting pockets ...\")\n",
    "    for rank, (p_id, p_points) in enumerate(pockets.items()):\n",
    "        save_points_to_pdb(p_points, f\"{output_dir}/step3_pocket_{rank}.pdb\")\n",
    "\n",
    "    print(f\"\\nExport complete. {len(pockets)} pocket files saved.\")\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "# FIX: guard now checks 'clean_atoms', not 'atoms'\n",
    "if 'clean_atoms' in locals():\n",
    "    export_all_steps(clean_atoms, output_dir=\"pocket_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Residue Extraction — Identifying Pocket-Lining Residues\n",
    "\n",
    "After identifying the pocket clusters, we determine **which amino acids form the pocket walls**.\n",
    "\n",
    "For each pocket point, we search for nearby protein atoms using a **KDTree**.\n",
    "If any atom of a residue lies within a distance threshold, the entire residue is considered part of the pocket.\n",
    "\n",
    "### How it works\n",
    "For every pocket point, we find all protein atoms within `threshold` (4.5 Å).\n",
    "Any residue owning at least one such atom is considered a lining residue.\n",
    "\n",
    "### Why 4.5 Å?\n",
    "\n",
    "This distance captures typical ligand–protein interactions, including:\n",
    "\n",
    "* Van der Waals contacts (~3.5 Å)\n",
    "* Hydrogen bonds donor/acceptor pairs (~3.5–4.0 Å)\n",
    "* Electrostatic interactions (~4.5 Å)\n",
    "\n",
    "### Output\n",
    "\n",
    "For each pocket, a text file lists:\n",
    "\n",
    "* Pocket ID and number of grid points\n",
    "* All lining residues in `NAME-ChainSeq` format (e.g., HIS-H195, GLU-H198)\n",
    "\n",
    "This provides the biological context of each predicted binding site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "step6-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Grid created: 174,900 points at 1.0 Å spacing.\n",
      " Neighbor count in 6.5 Å radius -> Min: 2, Max: 77, Mean: 20.7\n",
      "Filtered: 174,900 → 5,009 pocket candidates (2.9% remaining).\n",
      "0 pockets found (5009 noise points discarded):\n",
      "\n",
      "Residue report saved to: pocket_residues.txt\n"
     ]
    }
   ],
   "source": [
    "def extract_and_save_residues(\n",
    "    pockets_dict: dict,\n",
    "    protein_atoms: list,\n",
    "    output_file: str = \"pocket_residues.txt\",\n",
    "    threshold: float = 4.5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Identifies all protein residues lining each pocket and saves them to a text file.\n",
    "\n",
    "    A residue is considered a pocket-lining residue if any of its atoms\n",
    "    lies within `threshold` Å of any pocket point.\n",
    "\n",
    "    Parameters:\n",
    "        pockets_dict:  dictionary {pocket_id: np.ndarray of pocket points}\n",
    "        protein_atoms: list of Biopython Atom objects\n",
    "        output_file:   path to save the residue report\n",
    "        threshold:     maximum distance from pocket point to atom in Å\n",
    "    \"\"\"\n",
    "    # Build a KDTree over all protein atom coordinates for fast lookup\n",
    "    atom_coords = np.array([atom.get_coord() for atom in protein_atoms])\n",
    "    tree = KDTree(atom_coords)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"LIGAND BINDING SITE PREDICTIONS — RESIDUE LIST\\n\\n\")\n",
    "\n",
    "        for p_id, points in pockets_dict.items():\n",
    "            # For every pocket point, find all atom indices within threshold\n",
    "            neighbor_indices = tree.query_ball_point(points, threshold)\n",
    "\n",
    "            # Flatten to a set of unique atom indices\n",
    "            flat_indices = set(idx for sublist in neighbor_indices for idx in sublist)\n",
    "\n",
    "            # Map atom indices → unique residue identifiers\n",
    "            found_residues = set()\n",
    "            for idx in flat_indices:\n",
    "                res = protein_atoms[idx].get_parent()\n",
    "                chain_id = res.get_parent().id\n",
    "                hetflag, resseq, icode = res.id\n",
    "                resnum = f\"{resseq}{icode.strip()}\"\n",
    "                # Format: RESNAME-ChainResnum, e.g. HIS-H195\n",
    "                res_info = f\"{res.get_resname()}-{chain_id}{resnum}\"\n",
    "                found_residues.add(res_info)\n",
    "\n",
    "            sorted_res = sorted(found_residues)\n",
    "\n",
    "            f.write(f\"Pocket {p_id} ({len(points)} points):\\n\")\n",
    "            f.write(f\"Lining Residues: {', '.join(sorted_res)}\\n\\n\")\n",
    "\n",
    "            print(f\"   Pocket {p_id}: {len(sorted_res)} lining residues identified.\")\n",
    "\n",
    "    print(f\"\\nResidue report saved to: {output_file}\")\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "# FIX: guard checks 'clean_atoms', not 'atoms'\n",
    "if 'clean_atoms' in locals():\n",
    "    full_grid = create_search_grid(clean_atoms, spacing=1.0)\n",
    "    pocket_candidates = find_pocket_points(full_grid, clean_atoms)\n",
    "    pockets_dict = cluster_pocket_points(pocket_candidates)\n",
    "    extract_and_save_residues(pockets_dict, clean_atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6b-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 6b. Evolutionary Conservation Scoring\n",
    "\n",
    "Binding pockets are not only geometric — they are also **evolutionarily conserved**.\n",
    "A pocket lining that is invariant across related species is far more likely to be a true functional binding site.\n",
    "\n",
    "### How conservation is calculated\n",
    "\n",
    "A **Multiple Sequence Alignment (MSA)** of homologous proteins is read from a FASTA file.\n",
    "The first sequence in the alignment is assumed to be the target protein matching the PDB structure.\n",
    "\n",
    "For each alignment column, a conservation score between **0.0** and **1.0** is computed as:\n",
    "\n",
    "```\n",
    "score = count(most_common_residue) / count(all_sequences_in_alignment)\n",
    "```\n",
    "\n",
    "This penalises columns where many species have a gap (insertion/deletion) at that position.\n",
    "\n",
    "These column-level scores are then mapped to individual PDB residue numbers by tracking\n",
    "non-gap positions in the target sequence. Chain IDs are included in residue keys to\n",
    "handle multi-chain structures correctly.\n",
    "\n",
    "### Pocket filtering\n",
    "\n",
    "Each predicted pocket is evaluated by computing the **average conservation score of its\n",
    "lining residues** (atoms within `threshold_dist` Å of any pocket point).\n",
    "\n",
    "Pockets whose average score falls below `min_score` are discarded.\n",
    "\n",
    "| `min_score` | Interpretation |\n",
    "| ----------- | -------------- |\n",
    "| 0.0 | No filter (keep everything) |\n",
    "| 0.45 | Recommended default — retains moderately conserved sites |\n",
    "| 1.0 | Only perfectly conserved pockets (almost nothing survives) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "step6b-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-letter to 1-letter amino acid code lookup\n",
    "AA_3_TO_1 = {\n",
    "    'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E', 'PHE': 'F',\n",
    "    'GLY': 'G', 'HIS': 'H', 'ILE': 'I', 'LYS': 'K', 'LEU': 'L',\n",
    "    'MET': 'M', 'ASN': 'N', 'PRO': 'P', 'GLN': 'Q', 'ARG': 'R',\n",
    "    'SER': 'S', 'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_conservation_scores(\n",
    "    alignment_file: str,\n",
    "    protein_atoms: list,\n",
    "    aln_format: str = \"fasta\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Reads a Multiple Sequence Alignment (MSA) and calculates a conservation score\n",
    "    (0.0 to 1.0) for each amino acid position. Maps scores to PDB residue keys\n",
    "    in the format 'ChainID_ResSeq' (e.g. 'H_50').\n",
    "\n",
    "    The score for each column is:\n",
    "        most_common_residue_count / total_sequences_in_alignment\n",
    "    This penalises columns with many gaps across species.\n",
    "\n",
    "    The first sequence in the alignment is assumed to be the target protein.\n",
    "\n",
    "    Parameters:\n",
    "        alignment_file: path to FASTA (or other format) MSA file\n",
    "        protein_atoms:  list of Biopython Atom objects from the cleaned structure\n",
    "        aln_format:     BioPython AlignIO format string (default: 'fasta')\n",
    "\n",
    "    Returns:\n",
    "        conservation_dict: {residue_key: score} e.g. {'H_50': 0.87, 'H_51': 0.42, ...}\n",
    "    \"\"\"\n",
    "    print(f\"Reading alignment from {alignment_file} ...\")\n",
    "    alignment = AlignIO.read(alignment_file, aln_format)\n",
    "    target_seq_aligned = str(alignment[0].seq)\n",
    "    num_sequences = len(alignment)\n",
    "\n",
    "    # 1. Calculate conservation score for each alignment column\n",
    "    col_scores = []\n",
    "    for i in range(alignment.get_alignment_length()):\n",
    "        column = alignment[:, i]\n",
    "        residues_no_gap = [r.upper() for r in column if r not in ('-', '.')]\n",
    "\n",
    "        if not residues_no_gap:\n",
    "            col_scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        counts = Counter(residues_no_gap)\n",
    "        most_common_count = counts.most_common(1)[0][1]\n",
    "        # Denominator = all sequences (including those with a gap here)\n",
    "        # This penalises insertion/deletion positions\n",
    "        conservation_ratio = most_common_count / num_sequences\n",
    "        col_scores.append(conservation_ratio)\n",
    "\n",
    "    # 2. Build ordered list of PDB residue keys from atom list (chain-aware)\n",
    "    pdb_residues = []\n",
    "    full_pdb_seq = \"\"\n",
    "    for atom in protein_atoms:\n",
    "        res = atom.get_parent()\n",
    "        chain_id = res.get_parent().id\n",
    "        resseq = res.id[1]\n",
    "        res_key = f\"{chain_id}_{resseq}\"\n",
    "\n",
    "        if not pdb_residues or pdb_residues[-1] != res_key:\n",
    "            pdb_residues.append(res_key)\n",
    "            full_pdb_seq += AA_3_TO_1.get(res.get_resname(), \"X\")\n",
    "\n",
    "    # 3. Find alignment offset (handles truncated or offset structures)\n",
    "    aligned_seq_no_gaps = target_seq_aligned.replace('-', '').replace('.', '').upper()\n",
    "    offset = full_pdb_seq.find(aligned_seq_no_gaps)\n",
    "\n",
    "    if offset == -1:\n",
    "        print(\"\\n[WARNING] Alignment does not match structure exactly. Falling back to offset=0.\")\n",
    "        offset = 0\n",
    "    else:\n",
    "        print(f\"\\n[OK] Alignment offset found: starts at residue {offset + 1} in the 3D structure.\")\n",
    "\n",
    "    # 4. Map alignment columns to PDB residue keys\n",
    "    conservation_dict = {}\n",
    "    pdb_idx = offset\n",
    "\n",
    "    for i, char in enumerate(target_seq_aligned):\n",
    "        if char not in ('-', '.'):\n",
    "            if pdb_idx < len(pdb_residues):\n",
    "                res_key = pdb_residues[pdb_idx]\n",
    "                conservation_dict[res_key] = col_scores[i]\n",
    "                pdb_idx += 1\n",
    "\n",
    "    print(f\"Calculated conservation scores for {len(conservation_dict)} residues.\")\n",
    "    return conservation_dict\n",
    "\n",
    "\n",
    "def filter_pockets_by_conservation(\n",
    "    pockets_dict: dict,\n",
    "    protein_atoms: list,\n",
    "    conservation_dict: dict,\n",
    "    threshold_dist: float = 4.5,\n",
    "    min_score: float = 0.45\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Filters predicted pockets, retaining only those whose lining residues\n",
    "    have an average conservation score >= min_score.\n",
    "\n",
    "    Parameters:\n",
    "        pockets_dict:      {pocket_id: np.ndarray of pocket points}\n",
    "        protein_atoms:     list of Biopython Atom objects\n",
    "        conservation_dict: {residue_key: score} from calculate_conservation_scores\n",
    "        threshold_dist:    distance (Å) used to define lining residues\n",
    "        min_score:         minimum average conservation score to retain a pocket.\n",
    "                           Range 0.0–1.0. Recommended default: 0.45.\n",
    "\n",
    "    Returns:\n",
    "        conserved_pockets: filtered dict with new consecutive integer keys\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Filtering Pockets by Evolutionary Conservation ---\")\n",
    "\n",
    "    atom_coords = np.array([atom.get_coord() for atom in protein_atoms])\n",
    "    tree = KDTree(atom_coords)\n",
    "\n",
    "    conserved_pockets = {}\n",
    "\n",
    "    for p_id, points in pockets_dict.items():\n",
    "        neighbor_indices = tree.query_ball_point(points, threshold_dist)\n",
    "        flat_indices = set(idx for sublist in neighbor_indices for idx in sublist)\n",
    "\n",
    "        # Collect unique residue keys (chain-aware)\n",
    "        pocket_res_keys = set()\n",
    "        for idx in flat_indices:\n",
    "            res = protein_atoms[idx].get_parent()\n",
    "            chain_id = res.get_parent().id\n",
    "            resseq = res.id[1]\n",
    "            pocket_res_keys.add(f\"{chain_id}_{resseq}\")\n",
    "\n",
    "        scores = [conservation_dict.get(r_key, 0.0) for r_key in pocket_res_keys]\n",
    "\n",
    "        if not scores:\n",
    "            continue\n",
    "\n",
    "        avg_score = sum(scores) / len(scores)\n",
    "\n",
    "        if avg_score >= min_score:\n",
    "            print(f\"   [KEEP] Pocket {p_id:2d}: Avg Score = {avg_score:.2f} \"\n",
    "                  f\"({len(pocket_res_keys)} residues)\")\n",
    "            conserved_pockets[p_id] = points\n",
    "        else:\n",
    "            print(f\"   [DROP] Pocket {p_id:2d}: Avg Score = {avg_score:.2f} (Too low)\")\n",
    "\n",
    "    print(f\"\\nResult: {len(conserved_pockets)} out of {len(pockets_dict)} pockets \"\n",
    "          f\"passed the conservation filter.\")\n",
    "\n",
    "    # Re-index remaining pockets consecutively from 1\n",
    "    final_pockets = {i + 1: pts for i, pts in enumerate(conserved_pockets.values())}\n",
    "    return final_pockets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Chemical Analysis & Pocket Ranking\n",
    "\n",
    "Not all pockets are equally suitable for ligand binding. We analyze the **chemical environment**\n",
    "of each pocket to determine what type of ligand is most likely to bind there.\n",
    "\n",
    "### Chemical Classification of Amino Acids\n",
    "\n",
    "Residues are divided into **five chemical groups** (consistent with the code below):\n",
    "\n",
    "| Group                  | Residues                          | Properties                          |\n",
    "| ---------------------- | --------------------------------- | ----------------------------------- |\n",
    "| **Hydrophobic**        | ALA, VAL, LEU, ILE, MET, PHE, TRP | Favor non-polar, lipophilic ligands |\n",
    "| **Polar (uncharged)**  | SER, THR, ASN, GLN, TYR           | Form hydrogen bonds                 |\n",
    "| **Positively charged** | LYS, ARG, HIS                     | Attract negatively charged ligands  |\n",
    "| **Negatively charged** | ASP, GLU                          | Attract positively charged ligands  |\n",
    "| **Special cases**      | GLY, PRO, CYS                     | Structural roles; CYS can form disulfide bonds; PRO constrains backbone |\n",
    "\n",
    "### Ranking Score\n",
    "\n",
    "Each pocket receives a score:\n",
    "```\n",
    "score = size_score + chemistry_bonus\n",
    "```\n",
    "where `size_score = number of grid points` (volume proxy) and\n",
    "`chemistry_bonus` weights charged and polar residues more heavily\n",
    "(better interaction potential with drug-like molecules).\n",
    "\n",
    "### Output\n",
    "\n",
    "For each pocket: rank, score, preferred ligand type, chemical composition, and lining residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "step7-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- POCKET RANKING ---\n",
      "\n",
      "Saved to pocket_ranking.txt\n"
     ]
    }
   ],
   "source": [
    "def analyze_and_rank_pockets(\n",
    "    pockets_dict: dict,\n",
    "    protein_atoms: list,\n",
    "    threshold: float = 4.5\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Chemical analysis and ranking of binding pockets.\n",
    "\n",
    "    Each pocket is evaluated based on:\n",
    "    - Pocket size (volume proxy = number of grid points)\n",
    "    - Chemical composition of lining residues\n",
    "    - Hydrophobic vs. polar vs. charged balance\n",
    "\n",
    "    Residues are classified into 5 chemical groups:\n",
    "        Hydrophobic | Polar (uncharged) | Positive | Negative | Special\n",
    "\n",
    "    Parameters:\n",
    "        pockets_dict:  {pocket_id: np.ndarray of pocket points}\n",
    "        protein_atoms: list of Biopython Atom objects\n",
    "        threshold:     distance (Å) to define lining residues\n",
    "\n",
    "    Returns:\n",
    "        ranked_pockets: list of dicts, sorted by score descending\n",
    "    \"\"\"\n",
    "    # 5-group amino acid classification (consistent with Markdown table above)\n",
    "    HYDROPHOBIC = {'ALA', 'VAL', 'LEU', 'ILE', 'MET', 'PHE', 'TRP'}\n",
    "    POLAR       = {'SER', 'THR', 'ASN', 'GLN', 'TYR'}\n",
    "    POSITIVE    = {'LYS', 'ARG', 'HIS'}\n",
    "    NEGATIVE    = {'ASP', 'GLU'}\n",
    "    SPECIAL     = {'GLY', 'PRO', 'CYS'}   # structural roles; PRO + CYS moved here\n",
    "\n",
    "    # Build KDTree once over all protein atoms\n",
    "    atom_coords = np.array([atom.get_coord() for atom in protein_atoms])\n",
    "    tree = KDTree(atom_coords)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for p_id, points in pockets_dict.items():\n",
    "        neighbor_indices = tree.query_ball_point(points, threshold)\n",
    "        flat_indices = set(idx for sublist in neighbor_indices for idx in sublist)\n",
    "\n",
    "        # Collect unique residue objects (not atoms) to avoid double-counting\n",
    "        unique_residues = set()\n",
    "        for idx in flat_indices:\n",
    "            unique_residues.add(protein_atoms[idx].get_parent())\n",
    "\n",
    "        residues = [res.get_resname() for res in unique_residues]\n",
    "\n",
    "        # Count each chemical group\n",
    "        counts = {\n",
    "            'hydrophobic': sum(r in HYDROPHOBIC for r in residues),\n",
    "            'polar':       sum(r in POLAR       for r in residues),\n",
    "            'positive':    sum(r in POSITIVE    for r in residues),\n",
    "            'negative':    sum(r in NEGATIVE    for r in residues),\n",
    "            'special':     sum(r in SPECIAL     for r in residues),\n",
    "        }\n",
    "\n",
    "        total = sum(counts.values()) if sum(counts.values()) > 0 else 1\n",
    "\n",
    "        hydrophobic_ratio = counts['hydrophobic'] / total\n",
    "        polar_ratio       = counts['polar']       / total\n",
    "        charge_ratio      = (counts['positive'] + counts['negative']) / total\n",
    "\n",
    "        # Determine ligand type preference\n",
    "        if charge_ratio > 0.30:\n",
    "            preference = \"Charged Ligands\"\n",
    "        elif hydrophobic_ratio > 0.50:\n",
    "            preference = \"Hydrophobic Ligands\"\n",
    "        elif polar_ratio > 0.30:\n",
    "            preference = \"Polar Ligands\"\n",
    "        else:\n",
    "            preference = \"Mixed Ligands\"\n",
    "\n",
    "        # Scoring: size + chemistry bonus (charged/polar residues weighted higher)\n",
    "        size_score = len(points)\n",
    "        chemistry_bonus = (\n",
    "            counts['hydrophobic'] * 2 +\n",
    "            counts['polar']       * 2 +\n",
    "            counts['positive']    * 3 +\n",
    "            counts['negative']    * 3\n",
    "        )\n",
    "        score = size_score + chemistry_bonus\n",
    "\n",
    "        results.append({\n",
    "            'id':               p_id,\n",
    "            'size':             len(points),\n",
    "            'score':            score,\n",
    "            'preference':       preference,\n",
    "            'composition':      counts,\n",
    "            'hydrophobic_ratio': hydrophobic_ratio,\n",
    "            'polar_ratio':      polar_ratio,\n",
    "            'charge_ratio':     charge_ratio,\n",
    "            'residues':         sorted(residues),\n",
    "        })\n",
    "\n",
    "    ranked_pockets = sorted(results, key=lambda x: x['score'], reverse=True)\n",
    "    return ranked_pockets\n",
    "\n",
    "\n",
    "if 'pockets_dict' in locals():\n",
    "    ranked_list = analyze_and_rank_pockets(pockets_dict, clean_atoms)\n",
    "\n",
    "    print(\"\\n--- POCKET RANKING ---\\n\")\n",
    "\n",
    "    with open(\"pocket_ranking.txt\", \"w\") as f:\n",
    "        f.write(\"BINDING SITE ANALYSIS\\n\\n\")\n",
    "\n",
    "        for i, p in enumerate(ranked_list):\n",
    "            text = (\n",
    "                f\"Rank {i+1} | Pocket {p['id']} | Score: {p['score']}\\n\"\n",
    "                f\"Size: {p['size']} grid points\\n\"\n",
    "                f\"Preferred Ligand Type: {p['preference']}\\n\"\n",
    "                f\"Composition:\\n\"\n",
    "                f\"  Hydrophobic: {p['composition']['hydrophobic']}\\n\"\n",
    "                f\"  Polar:       {p['composition']['polar']}\\n\"\n",
    "                f\"  Positive:    {p['composition']['positive']}\\n\"\n",
    "                f\"  Negative:    {p['composition']['negative']}\\n\"\n",
    "                f\"  Special:     {p['composition']['special']}\\n\"\n",
    "                f\"Residues:\\n\"\n",
    "                f\"  {', '.join(p['residues'])}\\n\\n\"\n",
    "            )\n",
    "            print(text)\n",
    "            f.write(text)\n",
    "\n",
    "    print(\"Saved to pocket_ranking.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step8-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Validation Test — Checking the Analysis\n",
    "\n",
    "Before trusting the results, we run a structured sanity check:\n",
    "\n",
    "1. **Was a top pocket found?** → Confirms the pipeline produced at least one meaningful result\n",
    "2. **Is the polarity ratio sensible?** → Extreme values (0.0 or 1.0) may indicate a data issue\n",
    "3. **Are polar and non-polar pockets both represented?** → A healthy dataset should have both\n",
    "\n",
    "This test cell is useful to re-run after changing parameters like `spacing`, `min_dist`, or `eps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "step8-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: Validating Chemical Analysis & Ranking...\n",
      " FAILED: No pockets available for analysis.\n"
     ]
    }
   ],
   "source": [
    "def test_final_analysis(pockets_dict: dict, protein_atoms: list) -> None:\n",
    "    \"\"\"\n",
    "    Runs a structured validation of the chemical analysis and ranking.\n",
    "    Prints a summary of the top pocket and overall statistics.\n",
    "\n",
    "    Parameters:\n",
    "        pockets_dict:  dictionary {pocket_id: np.ndarray of pocket points}\n",
    "        protein_atoms: list of Biopython Atom objects\n",
    "    \"\"\"\n",
    "    print(\"Step 8: Validating Chemical Analysis & Ranking...\")\n",
    "\n",
    "    ranked_results = analyze_and_rank_pockets(pockets_dict, protein_atoms)\n",
    "\n",
    "    if not ranked_results:\n",
    "        print(\" FAILED: No pockets available for analysis.\")\n",
    "        return\n",
    "\n",
    "    # Check 1: Top pocket summary\n",
    "    top = ranked_results[0]\n",
    "    print(f\"\\n TOP PREDICTED BINDING SITE: Pocket {top['id']}\")\n",
    "    print(f\"   Size (grid points): {top['size']}\")\n",
    "    print(f\"   Best suited for:    {top['preference']}\")\n",
    "    print(f\"   Polarity ratio:     {top['polar_ratio']:.1%} polar residues\")\n",
    "    print(f\"   Key residues:       {', '.join(top['residues'][:8])}\"\n",
    "          f\"{'...' if len(top['residues']) > 8 else ''}\")\n",
    "\n",
    "    # Check 2: Overall statistics\n",
    "    hydrophobic_pockets = [int(p['id']) for p in ranked_results if p['preference'] == \"Hydrophobic Ligands\"]\n",
    "    polar_pockets       = [int(p['id']) for p in ranked_results if p['preference'] == \"Polar Ligands\"]\n",
    "    charged_pockets     = [int(p['id']) for p in ranked_results if p['preference'] == \"Charged Ligands\"]\n",
    "    mixed_pockets       = [int(p['id']) for p in ranked_results if p['preference'] == \"Mixed Ligands\"]\n",
    "\n",
    "    print(f\"\\n--- Summary Statistics ---\")\n",
    "    print(f\"   Total pockets found:      {len(ranked_results)}\")\n",
    "    print(f\"   Hydrophobic pockets:      {len(hydrophobic_pockets)}\")\n",
    "    print(f\"   Polar pockets:            {len(polar_pockets)}\")\n",
    "    print(f\"   Charged pockets:          {len(charged_pockets)}\")\n",
    "    print(f\"   Mixed chemistry pockets:  {len(mixed_pockets)}\")\n",
    "\n",
    "    print(\"\\nPocket IDs by category:\")\n",
    "    print(f\"   Hydrophobic: {hydrophobic_pockets}\")\n",
    "    print(f\"   Polar:       {polar_pockets}\")\n",
    "    print(f\"   Charged:     {charged_pockets}\")\n",
    "    print(f\"   Mixed:       {mixed_pockets}\")\n",
    "\n",
    "    # Check 3: Sanity check on top pocket\n",
    "    if top['size'] > 0 and 0.0 < top['polar_ratio'] < 1.0:\n",
    "        print(\"\\nSUCCESS: Analysis looks biologically reasonable.\")\n",
    "    elif top['polar_ratio'] in (0.0, 1.0):\n",
    "        print(\"\\n WARNING: Extreme polarity ratio — check residue classification.\")\n",
    "    else:\n",
    "        print(\"\\nWARNING: Unexpected result — check input data.\")\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "if 'pockets_dict' in locals():\n",
    "    test_final_analysis(pockets_dict, clean_atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step9-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Full Pipeline with Conservation Filtering\n",
    "\n",
    "`run_full_prediction` is the **master orchestration function** that chains all steps into a single call.\n",
    "\n",
    "### Pipeline order\n",
    "\n",
    "| Step | Function | Purpose |\n",
    "| ---- | -------- | ------- |\n",
    "| 1 | `create_search_grid` | Build uniform 3D grid around the protein |\n",
    "| 2 | `find_pocket_points` | Filter grid to surface-accessible candidates |\n",
    "| 3 | `cluster_pocket_points` | Group candidates into discrete pockets (DBSCAN) |\n",
    "| 4 | `calculate_conservation_scores` | Derive per-residue conservation from MSA |\n",
    "| 5 | `filter_pockets_by_conservation` | Discard pockets below the conservation threshold |\n",
    "| 6 | `analyze_and_rank_pockets` | Chemical scoring and ranking of surviving pockets |\n",
    "| 7 | `save_points_to_pdb` | Export conserved pockets directly (not a pipeline re-run) |\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* `clean_atoms` must be available (output of Step 1c)\n",
    "* An `alignment.fasta` MSA file must be present in the working directory\n",
    "\n",
    "### Reading the Final Output\n",
    "\n",
    "| Field | What it means |\n",
    "|-------|---------------|\n",
    "| `RANK 1` | Most likely binding site (highest score) |\n",
    "| `Score` | Size + chemistry bonus (larger = more promising) |\n",
    "| `Preferred Ligand Type` | Guides ligand selection strategy |\n",
    "| `% polar` | Fraction of lining residues that are polar |\n",
    "| `Key Residues` | First 8 unique amino acids lining the pocket |\n",
    "\n",
    "> **Drug discovery context:** A high-score pocket with HIS, ASP, or GLU residues\n",
    "> is a strong indicator of a catalytic site — ideal for competitive inhibitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "step9-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pipeline...\n",
      "\n",
      " Grid created: 174,900 points at 1.0 Å spacing.\n",
      " Neighbor count in 6.5 Å radius -> Min: 2, Max: 77, Mean: 20.7\n",
      "Filtered: 174,900 → 5,009 pocket candidates (2.9% remaining).\n",
      "14 pockets found (2585 noise points discarded):\n",
      "   Pocket 1:  175 points | Center: (8.9, -8.5, 6.9)\n",
      "   Pocket 2:  152 points | Center: (12.0, -13.1, 20.9)\n",
      "   Pocket 3:  145 points | Center: (4.3, 5.6, 30.0)\n",
      "   Pocket 4:  118 points | Center: (14.0, -1.0, 36.1)\n",
      "   Pocket 5:   95 points | Center: (21.7, -13.2, 24.6)\n",
      "   Pocket 6:   91 points | Center: (31.7, 4.8, 18.1)\n",
      "   Pocket 7:   91 points | Center: (17.5, 9.0, 2.3)\n",
      "   Pocket 8:   77 points | Center: (0.8, 5.2, 8.2)\n",
      "   Pocket 9:   73 points | Center: (3.0, -17.1, 22.5)\n",
      "   Pocket 10:   73 points | Center: (11.7, 14.2, 32.7)\n",
      "   Pocket 11:   69 points | Center: (8.4, 13.3, 20.6)\n",
      "   Pocket 12:   63 points | Center: (-0.9, -11.3, 18.9)\n",
      "   Pocket 13:   63 points | Center: (19.7, 6.0, 34.8)\n",
      "   Pocket 14:   63 points | Center: (24.2, 8.9, 30.2)\n",
      "Reading alignment from alignment.fasta ...\n",
      "\n",
      "[WARNING] Alignment does not match structure exactly. Falling back to offset=0.\n",
      "Calculated conservation scores for 237 residues.\n",
      "\n",
      "--- SANITY CHECK: First 10 residue conservation scores ---\n",
      "  Residue H_16: Score = 0.22\n",
      "  Residue H_17: Score = 0.32\n",
      "  Residue H_18: Score = 0.43\n",
      "  Residue H_19: Score = 0.62\n",
      "  Residue H_20: Score = 0.11\n",
      "  Residue H_21: Score = 0.25\n",
      "  Residue H_22: Score = 0.27\n",
      "  Residue H_23: Score = 0.11\n",
      "  Residue H_24: Score = 0.21\n",
      "  Residue H_25: Score = 0.33\n",
      "\n",
      "--- Filtering Pockets by Evolutionary Conservation ---\n",
      "   [DROP] Pocket  1: Avg Score = 0.20 (Too low)\n",
      "   [DROP] Pocket  2: Avg Score = 0.40 (Too low)\n",
      "   [KEEP] Pocket  3: Avg Score = 0.49 (13 residues)\n",
      "   [DROP] Pocket  4: Avg Score = 0.32 (Too low)\n",
      "   [DROP] Pocket  5: Avg Score = 0.36 (Too low)\n",
      "   [DROP] Pocket  6: Avg Score = 0.40 (Too low)\n",
      "   [DROP] Pocket  7: Avg Score = 0.22 (Too low)\n",
      "   [DROP] Pocket  8: Avg Score = 0.29 (Too low)\n",
      "   [DROP] Pocket  9: Avg Score = 0.30 (Too low)\n",
      "   [DROP] Pocket 10: Avg Score = 0.39 (Too low)\n",
      "   [KEEP] Pocket 11: Avg Score = 0.49 (10 residues)\n",
      "   [DROP] Pocket 12: Avg Score = 0.28 (Too low)\n",
      "   [DROP] Pocket 13: Avg Score = 0.25 (Too low)\n",
      "   [DROP] Pocket 14: Avg Score = 0.23 (Too low)\n",
      "\n",
      "Result: 2 out of 14 pockets passed the conservation filter.\n",
      " Saved: final_conserved_pockets/conserved_pocket_0.pdb (145 points)\n",
      " Saved: final_conserved_pockets/conserved_pocket_1.pdb (69 points)\n",
      "\n",
      "Exported 2 conserved pocket(s) to 'final_conserved_pockets/'\n"
     ]
    }
   ],
   "source": [
    "def run_full_prediction(\n",
    "    protein_atoms: list,\n",
    "    alignment_file: str = None,\n",
    "    spacing: float = 1.0,\n",
    "    output_dir: str = \"final_conserved_pockets\"\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Runs the complete binding pocket prediction pipeline end-to-end,\n",
    "    including optional evolutionary conservation filtering.\n",
    "\n",
    "    Parameters:\n",
    "        protein_atoms:  list of Biopython Atom objects (cleaned protein)\n",
    "        alignment_file: path to FASTA MSA file (optional — filter disabled if None)\n",
    "        spacing:        grid spacing in Å (default 1.0)\n",
    "        output_dir:     directory for exported PDB files\n",
    "\n",
    "    Returns:\n",
    "        ranked_results:     list of ranked pocket dicts\n",
    "        conserved_pockets:  dict of pockets that passed conservation filter\n",
    "        all_pockets:        dict of all geometry pockets before filtering\n",
    "    \"\"\"\n",
    "    print(\"Starting Pipeline...\\n\")\n",
    "\n",
    "    # 1. Grid generation\n",
    "    full_grid = create_search_grid(protein_atoms, spacing=spacing)\n",
    "\n",
    "    # 2. Grid filtering\n",
    "    pocket_candidates = find_pocket_points(full_grid, protein_atoms)\n",
    "\n",
    "    # 3. Clustering\n",
    "    all_pockets = cluster_pocket_points(pocket_candidates, eps=1.5, min_samples=15)\n",
    "\n",
    "    # 4. Conservation scoring + filtering (optional)\n",
    "    if alignment_file and os.path.isfile(alignment_file):\n",
    "        cons_scores = calculate_conservation_scores(alignment_file, protein_atoms)\n",
    "\n",
    "        print(\"\\n--- SANITY CHECK: First 10 residue conservation scores ---\")\n",
    "        for res_key, score in list(cons_scores.items())[:10]:\n",
    "            print(f\"  Residue {res_key}: Score = {score:.2f}\")\n",
    "\n",
    "        conserved_pockets = filter_pockets_by_conservation(\n",
    "            all_pockets,\n",
    "            protein_atoms,\n",
    "            conservation_dict=cons_scores,\n",
    "            threshold_dist=4.5,\n",
    "            min_score=0.45\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\n  WARNING: No alignment file provided or file not found.\")\n",
    "        print(\"   Conservation filter is DISABLED — all geometry pockets are used.\\n\")\n",
    "        conserved_pockets = all_pockets\n",
    "\n",
    "    if not conserved_pockets:\n",
    "        print(\"No conserved pockets found. Consider lowering min_score.\")\n",
    "        return [], {}, all_pockets\n",
    "\n",
    "    # 5. Chemical analysis on conserved pockets only\n",
    "    ranked_results = analyze_and_rank_pockets(conserved_pockets, protein_atoms)\n",
    "\n",
    "    # 6. Export conserved pockets\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for rank, (p_id, points) in enumerate(conserved_pockets.items()):\n",
    "        save_points_to_pdb(points, f\"{output_dir}/conserved_pocket_{rank}.pdb\")\n",
    "    print(f\"\\nExported {len(conserved_pockets)} conserved pocket(s) to '{output_dir}/'\")\n",
    "\n",
    "    return ranked_results, conserved_pockets, all_pockets\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "if 'clean_atoms' in locals():\n",
    "    final_ranked_pockets, final_pockets_dict, all_pockets_dict = run_full_prediction(\n",
    "        clean_atoms, alignment_file=\"alignment.fasta\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step10-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Combined Visualisation Export\n",
    "\n",
    "`save_protein_with_colored_pockets` writes a **single PDB file** containing both the protein\n",
    "and all predicted pocket points, making it easy to open one file and see everything.\n",
    "\n",
    "### Encoding scheme\n",
    "\n",
    "* Protein atoms are written as standard `ATOM` records.\n",
    "* Each pocket's grid points are written as `HETATM` records with residue name `PKT`.\n",
    "* Every pocket is assigned a **unique chain letter** using a sequential rank index —\n",
    "  not the raw pocket ID — so chain letters are always consecutive and never collide\n",
    "  with the protein chain.\n",
    "\n",
    "### Usage \n",
    "\n",
    "```python\n",
    "File → Open → protein_with_pockets.pdb\n",
    "color red,   chain A   # pocket rank 1\n",
    "color blue,  chain B   # pocket rank 2\n",
    "color green, chain C   # pocket rank 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "step10-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined file: protein_all_pockets.pdb\n",
      "Saved combined file: protein_conserved_pockets.pdb\n"
     ]
    }
   ],
   "source": [
    "POCKET_CHAIN_LETTERS = [c for c in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" if c != \"H\"]\n",
    "\n",
    "\n",
    "def save_protein_with_colored_pockets(\n",
    "    protein_atoms: list,\n",
    "    pockets_dict: dict,\n",
    "    output_file: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Saves the protein and all predicted pockets in a single PDB file.\n",
    "    Each pocket is written as a separate HETATM chain for easy coloring.\n",
    "    Atom serial numbers wrap at 99999 to stay within PDB format limits.\n",
    "\n",
    "    Parameters:\n",
    "        protein_atoms: list of Biopython Atom objects\n",
    "        pockets_dict:  {pocket_id: np.ndarray of pocket points}\n",
    "        output_file:   path for the combined output .pdb file\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        atom_id = 1\n",
    "\n",
    "        # Write protein atoms\n",
    "        for atom in protein_atoms:\n",
    "            res   = atom.get_parent()\n",
    "            chain = res.get_parent()\n",
    "            x, y, z = atom.get_coord()\n",
    "            serial = (atom_id % 99999) + 1\n",
    "\n",
    "            f.write(\n",
    "                f\"ATOM  {serial:5d} {atom.get_name():>4s} \"\n",
    "                f\"{res.get_resname():>3s} {chain.id:1s}\"\n",
    "                f\"{res.id[1]:4d}    \"\n",
    "                f\"{x:8.3f}{y:8.3f}{z:8.3f}\"\n",
    "                f\"  1.00  0.00           C\\n\"\n",
    "            )\n",
    "            atom_id += 1\n",
    "\n",
    "        # Write pocket points — one chain per pocket\n",
    "        for rank, (pocket_id, points) in enumerate(pockets_dict.items()):\n",
    "            chain_id = POCKET_CHAIN_LETTERS[rank % len(POCKET_CHAIN_LETTERS)]\n",
    "\n",
    "            for point in points:\n",
    "                x, y, z = point\n",
    "                serial = (atom_id % 99999) + 1\n",
    "\n",
    "                f.write(\n",
    "                    f\"HETATM{serial:5d}  P   PKT {chain_id}\"\n",
    "                    f\"{rank + 1:4d}    \"\n",
    "                    f\"{x:8.3f}{y:8.3f}{z:8.3f}\"\n",
    "                    f\"  1.00  0.00           P\\n\"\n",
    "                )\n",
    "                atom_id += 1\n",
    "\n",
    "        f.write(\"END\\n\")\n",
    "\n",
    "    print(\"Saved combined file:\", output_file)\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "if 'clean_atoms' in locals() and 'all_pockets_dict' in locals():\n",
    "    save_protein_with_colored_pockets(\n",
    "        clean_atoms,\n",
    "        all_pockets_dict,\n",
    "        \"protein_all_pockets.pdb\"\n",
    "    )\n",
    "    save_protein_with_colored_pockets(\n",
    "        clean_atoms,\n",
    "        final_pockets_dict,\n",
    "        \"protein_conserved_pockets.pdb\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
